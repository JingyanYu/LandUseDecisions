{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60524cdf",
   "metadata": {},
   "source": [
    "# Europe’s fragmenting urban landscape using high-resolution dynamic models to characterize spatial developments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Python modules\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "from scipy.ndimage import label\n",
    "from scipy.ndimage import labeled_comprehension\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm \n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0891fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CCA model from previous study\n",
    "import CCA_EU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f03085",
   "metadata": {},
   "source": [
    "# 1 Data and study area\n",
    "The GHSL built-up raster data publicly available with identifiers:\n",
    "\n",
    "- doi: 10.2905/jrc-ghsl-10007\n",
    "- PID: http://data.europa.eu/89h/jrc-ghsl-10007\n",
    "\n",
    "The functional urban area data publicly available with identifiers:\n",
    "\n",
    "- doi: 10.2905/347F0337-F2DA-4592-87B3-E25975EC2C95\n",
    "- PID: http://data.europa.eu/89h/347f0337-f2da-4592-87b3-e25975ec2c95\n",
    "\n",
    "Country boundaries are available through GISCO: \n",
    "\n",
    "- https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/countries\n",
    "\n",
    "Download the data into a (new) \"..\\data\" folder and unzip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of countries of interest\n",
    "countries = np.loadtxt('parameters\\europe_countries.txt', dtype=str).tolist()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the input data \n",
    "ghs_built_raster_paths = [\n",
    "    r'..\\data\\GHS_BUILT_LDS1975_GLOBE_R2018A_54009_250_V2_0\\GHS_BUILT_LDS1975_GLOBE_R2018A_54009_250_V2_0.tif',\n",
    "    r'..\\data\\GHS_BUILT_LDS1990_GLOBE_R2018A_54009_250_V2_0\\GHS_BUILT_LDS1990_GLOBE_R2018A_54009_250_V2_0.tif',\n",
    "    r'..\\data\\GHS_BUILT_LDS2000_GLOBE_R2018A_54009_250_V2_0\\GHS_BUILT_LDS2000_GLOBE_R2018A_54009_250_V2_0.tif',\n",
    "    r'..\\data\\GHS_BUILT_LDS2014_GLOBE_R2018A_54009_250_V2_0\\GHS_BUILT_LDS2014_GLOBE_R2018A_54009_250_V2_0.tif']\n",
    "\n",
    "fua_path = r'..\\data\\GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0\\GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.gpkg'\n",
    "\n",
    "nodata_value = -200\n",
    "\n",
    "# Function to binary reclassify GHSL urban percentage to binary urban, using 20% threshold\n",
    "def categorize_urban_vec(percent):\n",
    "    threshold = 20\n",
    "    out = np.full_like(percent, nodata_value)\n",
    "    out[(percent >= 0) & (percent < threshold) ] = 0\n",
    "    out[percent >= threshold] = 1\n",
    "    return out\n",
    "\n",
    "# Read the FUA file with global FUA's\n",
    "fua_gdf = gpd.read_file(fua_path)\n",
    "\n",
    "# Restrict dataset to countries and columns of interest\n",
    "countries_gpd = fua_gdf[fua_gdf['Cntry_name'].isin(countries)]\n",
    "countries_gpd = countries_gpd[['eFUA_name','Cntry_name','FUA_area','UC_area','geometry']]\n",
    "\n",
    "#create columns - urban units at 1975, 1990, 2000, 2014,and urban growth between 75-90, 90-00, 00-14\n",
    "def add_raster_to_dataframe(dataframe, raster_path, column_name):\n",
    "        def process(x):\n",
    "            shape = x['geometry']\n",
    "            with rio.open(raster_path) as src:    \n",
    "                out_img, out_transform = mask(src, [shape], crop=True)\n",
    "            fua_urban_raster = np.squeeze(categorize_urban_vec(out_img))\n",
    "            try:\n",
    "                x[column_name] = np.unique(fua_urban_raster,return_counts=True)[1][2]\n",
    "            except:\n",
    "                x[column_name] = np.nan\n",
    "            try:\n",
    "                x['Transform'] = out_transform;\n",
    "            except:\n",
    "                x['Transform'] = np.nan\n",
    "            try:\n",
    "                x[column_name + ' raster'] = fua_urban_raster.copy();\n",
    "            except:\n",
    "                x[column_name + ' raster'] = np.nan\n",
    "            return x\n",
    "        \n",
    "        dataframe = dataframe.apply(process, axis=1)\n",
    "        return dataframe\n",
    "        \n",
    "countries_gpd = add_raster_to_dataframe(countries_gpd, ghs_built_raster_paths[0],'1975 urban')\n",
    "countries_gpd = add_raster_to_dataframe(countries_gpd, ghs_built_raster_paths[1],'1990 urban')\n",
    "countries_gpd = add_raster_to_dataframe(countries_gpd, ghs_built_raster_paths[2],'2000 urban')\n",
    "countries_gpd = add_raster_to_dataframe(countries_gpd, ghs_built_raster_paths[3],'2014 urban')\n",
    "\n",
    "# Remove missing data\n",
    "countries_gpd.dropna(inplace=True)\n",
    "\n",
    "# Pre-calculate urban growth quantities\n",
    "countries_gpd['90-00 UG'] = countries_gpd['2000 urban']-countries_gpd['1990 urban'] \n",
    "countries_gpd['00-14 UG'] = countries_gpd['2014 urban']-countries_gpd['2000 urban'] \n",
    "countries_gpd['75-90 UG'] = countries_gpd['1990 urban']-countries_gpd['1975 urban'] \n",
    "\n",
    "#Keep only the FUAs with urban growth\n",
    "countries_gpd = countries_gpd[(countries_gpd['75-90 UG']>0)\n",
    "                              &(countries_gpd['90-00 UG']>0)\n",
    "                              &(countries_gpd['00-14 UG']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8041bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the eurostate Countries Administrative boundaries data publicly available at\n",
    "# https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/countries\n",
    "administrative_units_path =r'..\\data\\ref-countries-2020-01m.gdb\\ref-countries-2020-01m.gdb' \n",
    "eu_gdf = gpd.read_file(administrative_units_path).to_crs('ESRI:54009')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6806f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the GHSL names to eurostat country name\n",
    "country_names = countries\n",
    "country_names = [s.replace('UnitedKingdom', 'United Kingdom') for s in country_names]\n",
    "country_names = [s.replace('CzechRepublic', 'Czechia') for s in country_names]\n",
    "country_names = [s.replace('Turkey', 'Türkiye') for s in country_names]\n",
    "\n",
    "# Include neighbouring countries not analyzed for mapping\n",
    "non_OECDEU = ['Albania','Andorra','Armenia','Azerbaijan','Belarus','Bosnia and Herzegovina','Bulgaria',\n",
    "              'Croatia','Cyprus','Georgia','Kazakhstan','Latvia','Liechtenstein','Lithuania','Malta',\n",
    "              'Moldova','Monaco','Montenegro','North Macedonia','Romania','Russian Federation','San Marino',\n",
    "              'Serbia','Ukraine']\n",
    "bordering = ['Iran','Iraq','Syria']\n",
    "\n",
    "EU_map_countries = country_names + non_OECDEU + bordering\n",
    "\n",
    "# Adjust country name notation\n",
    "cntyname_annotations = [((1.10768e+06, 5.61764e+06), 'Austria'),((351980, 5.93993e+06), 'Belgium'),\n",
    "                        ((651122, 5.53395e+06), 'Switzerland'),((701612, 6.48093e+06), 'Denmark'),\n",
    "                        ((1.69881e+06, 6.74812e+06), 'Estonia'),((1.86961e+06, 4.67712e+06), 'Greece'),\n",
    "                        ((1.17062e+06, 5.84537e+06), 'Czechia'),((777853, 5.97984e+06), 'Germany'),\n",
    "                        ((200000, 5.5e+06), 'France'),((1.54904e+06, 7.26525e+06), 'Finland'),\n",
    "                        ((1.52867e+06, 5.57246e+06), 'Hungary'),((-593591, 6.20001e+06), 'Ireland'),\n",
    "                        ((1.00735e+06, 5.08358e+06), 'Italy'),((464790, 5.85001e+06), 'Luxembourg'),\n",
    "                        ((411353, 6.1078e+06), 'Netherlands'),((601144, 7.028e+06), 'Norway'),\n",
    "                        ((1.43573e+06, 6.08897e+06), 'Poland'),((-728429, 4.73992e+06), 'Portugal'),\n",
    "                        ((0.90898e+06, 7.09125e+06), 'Sweden'),((1.18201e+06, 5.46099e+06), 'Slovenia'),\n",
    "                        ((1.50621e+06, 5.73703e+06), 'Slovakia'),((3.01291e+06, 4.68042e+06), 'Türkiye'),\n",
    "                        ((-201445, 6.28578e+06), 'United Kingdom'),((-312991, 4.80445e+06), 'Spain')]\n",
    "\n",
    "# Map the study areas\n",
    "# Generate figure 3 in the article\n",
    "xmin, ymin, xmax, ymax = countries_gpd.total_bounds\n",
    "fig, axes = plt.subplots(1,1,figsize=(20,15))\n",
    "\n",
    "eu_gdf[eu_gdf['NAME_ENGL'].isin(non_OECDEU + bordering)].plot(ax=axes,ec='k',linewidth=0.8,color='white')\n",
    "eu_gdf[eu_gdf['NAME_ENGL'].isin(country_names)].plot(ax=axes,ec='k',linewidth=0.8,color='lightgrey')\n",
    "countries_gpd.plot(ax=axes,fc='darkgrey',ec='k',linewidth=0.6)\n",
    "axes.set_xlim(xmin, xmax) \n",
    "axes.set_ylim(ymin, ymax)\n",
    "axes.set_facecolor('lightblue')\n",
    "axes.tick_params(labelbottom=False,labelleft=False,axis=u'both', which=u'both',length=0)  \n",
    "for t in cntyname_annotations :\n",
    "    axes.annotate(text=t[1], xy=t[0], ha='center',fontsize=15,color='k',\n",
    "                  path_effects=[pe.withStroke(linewidth=4, foreground=\"salmon\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220cd8a",
   "metadata": {},
   "source": [
    "# 2 Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c8c8d",
   "metadata": {},
   "source": [
    "The parameters by scenarios can be found at: https://doi.org/10.6084/m9.figshare.22194244.v1\n",
    "\n",
    "These parameters were the results from previous study (https://doi.org/10.1016/j.compenvurbsys.2022.101892)\n",
    "\n",
    "After downloading, copy the parameters to a \"..\\parameters\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the parameters for each scenario, this is \n",
    "# Load the parameters for modelling growth using the four spatial development scenarios \n",
    "\n",
    "# 0 - compact; 1 - medium compact; 2 - medium dispersed; 3 - dispersed\n",
    "\n",
    "paras_fourscenarios = np.load(r'parameters\\paras_fourscenarios.npy',allow_pickle=True)\n",
    "seeds_fourscenarios = np.load(r'parameters\\seeds_fourscenarios.npy',allow_pickle=True)\n",
    "\n",
    "def get_random_parameters_for_scenario(scenario, size): \n",
    "    max_size = paras_fourscenarios[scenario].size\n",
    "    nums = np.random.choice(max_size, size=size, replace=False)\n",
    "    return paras_fourscenarios[scenario][nums], seeds_fourscenarios[scenario][nums] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_random_parameters_for_scenario(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to well-recognized spatial configuration metrics\n",
    "def largest_patch_size(obs):\n",
    "    obs_labeled_array, obs_num_features = label(obs)\n",
    "    obs_patch_sizes = labeled_comprehension(obs,obs_labeled_array,np.arange(1, obs_num_features+1), len, float, 0)\n",
    "    return np.amax(obs_patch_sizes)\n",
    "\n",
    "def patch_size(obs):\n",
    "    obs_labeled_array, obs_num_features = label(obs)\n",
    "#     obs_patch_sizes = labeled_comprehension(obs,obs_labeled_array,np.arange(1, obs_num_features+1), len, float, 0)\n",
    "    return obs_num_features\n",
    "\n",
    "# Defined by https://doi.org/10.1080/17538947.2018.1474957\n",
    "def DI(obs):\n",
    "    obs_labeled_array, obs_num_features = label(obs)\n",
    "    obs_patch_sizes = labeled_comprehension(obs,obs_labeled_array,np.arange(1, obs_num_features+1), len, float, 0)\n",
    "    NP = obs_num_features\n",
    "    LP = np.amax(obs_patch_sizes)/sum(obs_patch_sizes)*100\n",
    "    NPN = (NP-1)/(sum(obs_patch_sizes)-1)*100\n",
    "    LPN = (LP-1/sum(obs_patch_sizes))/(100-1/sum(obs_patch_sizes))*100\n",
    "    return (NPN+(100-LPN))/2\n",
    "\n",
    "#https://gist.github.com/viveksck/1110dfca01e4ec2c608515f0d5a5b1d1\n",
    "def fractal_dimension(Z, threshold=0.9):\n",
    "\n",
    "    # Only for 2d image\n",
    "    assert(len(Z.shape) == 2)\n",
    "\n",
    "    # From https://github.com/rougier/numpy-100 (#87)\n",
    "    def boxcount(Z, k):\n",
    "        S = np.add.reduceat(\n",
    "            np.add.reduceat(Z, np.arange(0, Z.shape[0], k), axis=0),\n",
    "                               np.arange(0, Z.shape[1], k), axis=1)\n",
    "\n",
    "        # We count non-empty (0) and non-full boxes (k*k)\n",
    "        return len(np.where((S > 0) & (S < k*k))[0])\n",
    "\n",
    "\n",
    "    # Transform Z into a binary array\n",
    "    Z = (Z < threshold)\n",
    "\n",
    "    # Minimal dimension of image\n",
    "    p = min(Z.shape)\n",
    "\n",
    "    # Greatest power of 2 less than or equal to p\n",
    "    n = 2**np.floor(np.log(p)/np.log(2))\n",
    "\n",
    "    # Extract the exponent\n",
    "    n = int(np.log(n)/np.log(2))\n",
    "\n",
    "    # Build successive box sizes (from 2**n down to 2**1)\n",
    "    sizes = 2**np.arange(n, 1, -1)\n",
    "\n",
    "    # Actual box counting with decreasing size\n",
    "    counts = []\n",
    "    for size in sizes:\n",
    "        counts.append(boxcount(Z, size))\n",
    "\n",
    "    # Fit the successive log(sizes) with log (counts)\n",
    "    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)\n",
    "    return -coeffs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27132034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function to visualize an FUA's real growth over 1975-2014 and four spatial development scenarios\n",
    "# ranging from compact to dispersed\n",
    "# Accompanied by the well-recognized spatial configuration metrics: fractal dimension and dispersion index\n",
    "\n",
    "def apply_scenario_1975_2014(country, fua, scenario_no):\n",
    "    country_data = countries_gpd[(countries_gpd['Cntry_name']==country)\n",
    "                                &(countries_gpd['eFUA_name']==fua)]\n",
    "\n",
    "    initial_map = country_data['1975 urban raster'].iloc[0].copy()\n",
    "    rando = np.random.randint(len(paras_fourscenarios[scenario_no]))\n",
    "    paras = paras_fourscenarios[scenario_no][rando]\n",
    "    seed = seeds_fourscenarios[scenario_no][rando]\n",
    "    total_growth = int(country_data['2014 urban'] - country_data['1975 urban'])\n",
    "    rows, cols = initial_map.shape\n",
    "    # set the increment size (default = 15)\n",
    "    growth_per_step = 15\n",
    "    # apply the model\n",
    "    final_map = CCA_EU.CCA_last_snapshot([paras[0], 0, paras[1]], [0, paras[2], paras[3]],\n",
    "                                         seed = seed, landmap = initial_map.copy(),\n",
    "                                         rows = rows, cols = cols, urban_num = total_growth,\n",
    "                                         trans_num = growth_per_step)\n",
    "    return final_map\n",
    "\n",
    "def calculate_metrics(raster):\n",
    "    r = raster.copy()\n",
    "    r[r==-200] = 0\n",
    "    di = DI(r)\n",
    "    fd = fractal_dimension(r)\n",
    "    return  di, fd\n",
    "\n",
    "def plot_20km_change_map(before, after, ax, transform, country_data):\n",
    "    # Set spatial extent: 20 X 20 km\n",
    "    \n",
    "    x = float(country_data['geometry'].centroid.x)\n",
    "    y = float(country_data['geometry'].centroid.y)\n",
    "    xmin, ymin, xmax, ymax = x-10000,y-10000,x+10000,y+10000\n",
    "    \n",
    "    changes = 2 * before + after\n",
    "    changes[ (after == -200) | (before == -200)] = 0\n",
    "    \n",
    "    cmap = ListedColormap([\"white\",\"k\",\"grey\", \"grey\"])\n",
    "    # Legend:\n",
    "    # 0 : non-built to non-built (white)\n",
    "    # 1 : non-built to built (black)\n",
    "    # 2 : built to non-built (should not exist, grey)\n",
    "    # 3 : built to built (grey)\n",
    "    \n",
    "    ax.set_xlim(xmin,xmax)\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.tick_params(labelbottom=False,labelleft=False,axis=u'both', which=u'both',length=0)\n",
    "       \n",
    "    country_data.boundary.plot(ax=ax,ec='darkgrey',linewidth=2)\n",
    "    \n",
    "    #interpolation = \"nearest\" turns of anti-aliasing of the pixels\n",
    "    show(changes, ax=ax, cmap=cmap,transform=transform,interpolation=\"nearest\")\n",
    "    \n",
    "def plot_fua_scenarios(country,fua):\n",
    "    country_data = countries_gpd[(countries_gpd['Cntry_name']==country)\n",
    "                                &(countries_gpd['eFUA_name']==fua)]\n",
    "    initial_map = country_data['1975 urban raster'].iloc[0]\n",
    "    \n",
    "    # calculate metrics for initial map\n",
    "    di_pre, fd_pre = calculate_metrics(initial_map);\n",
    "\n",
    "    \n",
    "    fig, axes = plt.subplots(5,1,figsize=(3,13))\n",
    "    \n",
    "    stat_superscripts = ['Obs','Cmp', 'MedCmpt', 'MedDisp', 'Disp']\n",
    "\n",
    "    for i in range(5):\n",
    "        if i == 0:\n",
    "            result_map = country_data['2014 urban raster'].iloc[0]\n",
    "        else:\n",
    "            scenario_no = i - 1\n",
    "            result_map = apply_scenario_1975_2014(country, fua, scenario_no)\n",
    "         \n",
    "        di, fd = calculate_metrics(result_map)\n",
    "        plot_20km_change_map(initial_map, result_map, axes[i], country_data['Transform'].iloc[0], country_data)\n",
    "        \n",
    "        if i==0:\n",
    "            axes[i].set_title('$DI^{Obs}_{1975}=%.2f \\quad FD^{Obs}_{1975}=%.2f$ \\n'%(di_pre,fd_pre) + \n",
    "                              '$DI^{Obs}_{2014}=%.2f \\quad FD^{Obs}_{2014}=%.2f$'%(di,fd))\n",
    "        else: \n",
    "            axes[i].set_title('$DI^{'+ stat_superscripts[i] +'}_{2014}=%.2f$'%(di) +\n",
    "                              '$\\quad FD^{'+ stat_superscripts[i] +'}_{2014}=%.2f$'%(fd))\n",
    "        \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate figure 4 & 5 in the article\n",
    "plot_fua_scenarios('Portugal','Braga')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b194a1",
   "metadata": {},
   "source": [
    "# 3. Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f04868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is from MCMCABC and CCA and should be probably imported rather than copied\n",
    "\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def kernel_expo_square(cutoff,beta):\n",
    "    '''\n",
    "    Input: 1. exponential decay cutoff value - cutoff, 2. exponential lambda - beta;\n",
    "    Output: a square exponential decay kernel matrix, \n",
    "            each entry has the exponential distance decay value from the square kernel's centre, normalised by the sum of the kernel.\n",
    "    Algorithm:\n",
    "    1. Given cutoff, calculate the distance where the cutoff value is reached, ceil round to the nearest larger integer a;\n",
    "    2. Using numpy.meshgrid to generate distance matrix cooridnates; vectorization calculate distance of each cell to the centre of the square;\n",
    "    3. Apply the exponential decay function to the distances matrix and return the normalized exponential decay kernel matrix.\n",
    "    '''\n",
    "    a = int(np.ceil(np.log(cutoff)/(-beta)))\n",
    "    centre_row, centre_col = a, a\n",
    "    xv, yv = np.meshgrid(np.arange(2*a+1),np.arange(2*a+1))\n",
    "    d_celltocentre = ((xv-centre_row)**2+(yv-centre_col)**2)**0.5\n",
    "    kernel = np.exp(-beta*d_celltocentre)\n",
    "    return kernel/sum(sum(kernel))\n",
    "\n",
    "kernels=[kernel_expo_square(0.01,beta) for beta in [0.2,0.5,2.0]]\n",
    "\n",
    "#function to measure the difference between an observation and a simulation map\n",
    "def ks_dis(obs,sim):\n",
    "    \"\"\"\n",
    "    This function measures the difference between an observation and a simulation map\n",
    "    using KS statistic.\n",
    "    Input: an observation and a simulation map - numpy arrays\n",
    "    Output: the sum of KS statistics on three spatial scales.\n",
    "    \"\"\"\n",
    "    obs_urbandensity0 = fftconvolve(obs,kernels[0],mode='same')[obs==1].flatten()\n",
    "    obs_urbandensity1 = fftconvolve(obs,kernels[1],mode='same')[obs==1].flatten()\n",
    "    obs_urbandensity2 = fftconvolve(obs,kernels[2],mode='same')[obs==1].flatten()\n",
    "    simulation_urbandensity0 = fftconvolve(sim,kernels[0],mode='same')[sim==1].flatten()\n",
    "    statistic0, pvalue = ks_2samp(obs_urbandensity0,simulation_urbandensity0)\n",
    "    simulation_urbandensity2 = fftconvolve(sim,kernels[2],mode='same')[sim==1].flatten()\n",
    "    statistic2, pvalue = ks_2samp(obs_urbandensity2,simulation_urbandensity2)\n",
    "    simulation_urbandensity1 = fftconvolve(sim,kernels[1],mode='same')[sim==1].flatten()\n",
    "    statistic1, pvalue = ks_2samp(obs_urbandensity1,simulation_urbandensity1)\n",
    "    return (statistic0 + statistic2 + statistic1) \n",
    "\n",
    "def calculate_distance(observed, simulated):\n",
    "    o = observed.copy()\n",
    "    s = simulated.copy()\n",
    "    o[o == -200] = 0\n",
    "    s[s == -200] = 0\n",
    "    return ks_dis(o,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e86e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each FUA and Period:\n",
    "#   Do 4 X 60 runs \n",
    "#   Calcute GOF\n",
    "#   Select 60 best runs\n",
    "#   Calculate percentage for each (soft classify)\n",
    "#   Identify best fit (hard classify)\n",
    "\n",
    "def run_model(before, after, param_set, seed):\n",
    "    n_before = np.count_nonzero(before == 1);\n",
    "    n_after = np.count_nonzero(after == 1);\n",
    "    total_growth = int(n_after - n_before)\n",
    "    rows, cols = before.shape\n",
    "    # set the increment size (default = 15)\n",
    "    growth_per_step = 15\n",
    "    # apply the model\n",
    "    final_map = CCA_EU.CCA_last_snapshot([param_set[0], 0, param_set[1]], [0, param_set[2], param_set[3]],\n",
    "                                         seed = seed, landmap = before.copy(),\n",
    "                                         rows = rows, cols = cols, urban_num = total_growth,\n",
    "                                         trans_num = growth_per_step)\n",
    "    \n",
    "    gof = calculate_distance(final_map, after) \n",
    "    return gof\n",
    "\n",
    "def run_period_single_fua(before, after):\n",
    "        gof = []\n",
    "        for s in range(4):\n",
    "            param_sets, seeds = get_random_parameters_for_scenario(s,60)\n",
    "            for p in range(60):\n",
    "                gof.append(run_model(before, after, param_sets[p], seeds[p]))\n",
    "\n",
    "        counts, bins = np.histogram(np.floor(np.argsort(gof)[:60]/60), range(5))  \n",
    "        soft_class = counts / 60\n",
    "        soft_class_dispersed = soft_class[3]\n",
    "        hard_class = np.argmax(counts)\n",
    "        return hard_class, soft_class, soft_class_dispersed\n",
    "\n",
    "def run_genesis_single_fua(after):\n",
    "    before = after.copy();\n",
    "    before[before==1] = 0;\n",
    "    return run_period_single_fua(before, after)\n",
    "\n",
    "def run_period(fua_row, before_str, after_str):\n",
    "    before = fua_row[before_str + ' urban raster'];\n",
    "    after = fua_row[after_str + ' urban raster'];\n",
    "    hard_class, soft_class, soft_class_dispersed = run_period_single_fua(before, after);\n",
    "    \n",
    "    return {before_str + '-' + after_str + ' dominant mode': hard_class,\n",
    "            before_str + '-' + after_str + ' dispersed': soft_class_dispersed}\n",
    "\n",
    "\n",
    "def run_genesis(fua_row, after_str):\n",
    "    after = fua_row[after_str + ' urban raster'];\n",
    "    hard_class, soft_class, soft_class_dispersed = run_genesis_single_fua(after);\n",
    "    return {'0-' + after_str + ' dominant mode': hard_class,\n",
    "            '0-' + after_str + ' dispersed': soft_class_dispersed}\n",
    "\n",
    "def run_period_multiple_fua(dataframe, before_str, after_str):\n",
    "    applied_df = dataframe.progress_apply(lambda row: run_period(row, before_str, after_str), axis='columns', result_type='expand')\n",
    "    dataframe = pd.concat([dataframe, applied_df], axis='columns')\n",
    "    return dataframe \n",
    "\n",
    "def run_genesis_multiple_fua(dataframe, after_str):\n",
    "    applied_df = dataframe.progress_apply(lambda row: run_genesis(row, after_str), axis='columns', result_type='expand')\n",
    "    dataframe = pd.concat([dataframe, applied_df], axis='columns')\n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05190e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is doing extensive analysis: 240 model runs for all FUA and for four periods. This may take days.\n",
    "\n",
    "print(\"0-1975\")\n",
    "countries_gpd = run_genesis_multiple_fua(countries_gpd,'1975')\n",
    "print(\"1975-1990\")\n",
    "countries_gpd = run_period_multiple_fua(countries_gpd,'1975','1990')\n",
    "print(\"1990-2000\")\n",
    "countries_gpd = run_period_multiple_fua(countries_gpd,'1990','2000')\n",
    "print(\"2000-2014\")\n",
    "countries_gpd = run_period_multiple_fua(countries_gpd,'2000','2014')\n",
    "\n",
    "# After all this work, make sure to store it for retrieval later\n",
    "countries_gpd.to_pickle(\"europe_results_countries_gpd.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_gpd = pd.read_pickle(\"europe_results_countries_gpd.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process for plotting\n",
    "values_075_avg = np.histogram(countries_gpd[\"0-1975 dominant mode\"].to_numpy(),range(5))\n",
    "values_7590_avg = np.histogram(countries_gpd[\"1975-1990 dominant mode\"].to_numpy(),range(5))\n",
    "values_9000_avg = np.histogram(countries_gpd[\"1990-2000 dominant mode\"].to_numpy(),range(5))\n",
    "values_0014_avg = np.histogram(countries_gpd[\"2000-2014 dominant mode\"].to_numpy(),range(5))\n",
    "\n",
    "countries_gpd['075color'] = countries_gpd[\"0-1975 dominant mode\"].apply(\n",
    "        lambda x: (x == 3 and 'blue') or (x == 2 and 'orange') \\\n",
    "        or (x == 1 and 'brown') or (x == 0 and 'green')) \n",
    "countries_gpd['7590color'] = countries_gpd[\"1975-1990 dominant mode\"].apply(\n",
    "        lambda x: (x == 3 and 'blue') or (x == 2 and 'orange') \\\n",
    "        or (x == 1 and 'brown') or (x == 0 and 'green')) \n",
    "countries_gpd['9000color'] = countries_gpd[\"1990-2000 dominant mode\"].apply(\n",
    "        lambda x: (x == 3 and 'blue') or (x == 2 and 'orange') \\\n",
    "        or (x == 1 and 'brown') or (x == 0 and 'green')) \n",
    "countries_gpd['0014color'] = countries_gpd[\"2000-2014 dominant mode\"].apply(\n",
    "        lambda x: (x == 3 and 'blue') or (x == 2 and 'orange') \\\n",
    "        or (x == 1 and 'brown') or (x == 0 and 'green')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84704c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_gpd['more_dispersed0014than7500'] = countries_gpd.apply(\n",
    "        lambda x: (x['1990-2000 dispersed'] > x['2000-2014 dispersed']  and 'blue') or \n",
    "    (x['1990-2000 dispersed'] <= x['2000-2014 dispersed'] and 'yellow'), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_map(colour_column,piechart_data, title): \n",
    "    xmin, ymin, xmax, ymax = countries_gpd.total_bounds\n",
    "    fig, axes = plt.subplots(1,1,figsize=(20,15))\n",
    "\n",
    "    eu_gdf[eu_gdf['NAME_ENGL'].isin(non_OECDEU + bordering)].plot(ax=axes,ec='k',linewidth=0.8,color='white')\n",
    "    eu_gdf[eu_gdf['NAME_ENGL'].isin(country_names)].plot(ax=axes,ec='k',linewidth=0.8,color='lightgrey')\n",
    "    for t in cntyname_annotations :\n",
    "        axes.annotate(text=t[1], xy=t[0], ha='center',fontsize=15)\n",
    "\n",
    "    countries_gpd.plot(ax=axes,color=countries_gpd[colour_column],ec='grey',linewidth=0.3)\n",
    "\n",
    "    left, bottom, width, height = [0.1, 0.7, 0.14, 0.14]\n",
    "    ax2 = fig.add_axes([left, bottom, width, height])\n",
    "    ax2.pie(piechart_data, colors=('green','brown', 'orange', 'blue'),autopct='%.0f%%',textprops={'fontsize': 20},pctdistance=1.3)\n",
    "    title='1975-1990'\n",
    "    plt.text(0.2, 0.95, title,horizontalalignment='center',fontsize=20,transform = axes.transAxes)\n",
    "    axes.set_xlim(xmin, xmax) \n",
    "    axes.set_ylim(ymin, ymax)\n",
    "    axes.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d15d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_map('075color', values_075_avg[0], '\"0\"-1975')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_map('7590color', values_7590_avg[0], '1975-1990')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9caf98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_map('9000color', values_9000_avg[0], '1990-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_map('0014color', values_0014_avg[0], '2000-2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate figure 2\n",
    "counts = countries_gpd['more_dispersed0014than7500'].value_counts()\n",
    "num_blue_avg = 0\n",
    "num_yellow_avg = 0\n",
    "if 'yellow' in counts:\n",
    "    num_yellow_avg = counts['yellow']\n",
    "\n",
    "if 'blue' in counts:\n",
    "    num_blue_avg = counts['blue']\n",
    "    \n",
    "pct_blue_avg = num_blue_avg / (num_green_avg + num_blue_avg)\n",
    "\n",
    "\n",
    "xmin, ymin, xmax, ymax = countries_gpd.total_bounds\n",
    "fig, axes = plt.subplots(1,1,figsize=(20,13))\n",
    "eu_gdf[eu_gdf['NAME_ENGL'].isin(non_OECDEU+bordering)].plot(ax=axes,ec='k',linewidth=0.8,color='white')\n",
    "eu_gdf[eu_gdf['NAME_ENGL'].isin(country_names)].plot(ax=axes,ec='k',linewidth=0.8,color='lightgrey')\n",
    "for t in cntyname_annotations :\n",
    "    axes.annotate(text=t[1], xy=t[0], ha='center',fontsize=15)\n",
    "\n",
    "countries_gpd.plot(ax=axes,color=countries_gpd['more_dispersed0014than7500'],ec='grey',linewidth=0.3)\n",
    "\n",
    "green_patch = mpatches.Patch(color='green', label='2000-2014 dispersion < 1975-1990:\\n %d' % (num_green_avg))\n",
    "blue_patch = mpatches.Patch(color='blue', label='2000-2014 dispersion > 1975-1990:\\n %d' % (num_blue_avg))\n",
    "_ = fig.legend(handles=[green_patch,blue_patch], bbox_to_anchor=(0.48,0.88),fontsize=18, ncol=1,\n",
    "               title=r\" %.0f%% more dispersed in 2000-2014 than 1975-1990\"  % (pct_blue_avg),\n",
    "               title_fontsize=18)\n",
    "\n",
    "axes.set_xlim(xmin, xmax) \n",
    "axes.set_ylim(ymin, ymax)\n",
    "axes.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
