{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4c1338",
   "metadata": {},
   "source": [
    "# 1. Install dependencies\n",
    "\n",
    "1. On windows, after installing Anaconda:     \n",
    "\n",
    "Open the Anaconda command window and run the following commands to install the necessary libraries\n",
    "\n",
    "pip install rasterio  \n",
    "pip install geopandas \n",
    "\n",
    "If necessary, you can find out more about installing rasterio and geopandas here: \n",
    "https://rasterio.readthedocs.io/en/latest/installation.html    \n",
    "https://geopandas.org/en/stable/getting_started/install.html\n",
    "\n",
    "2. clone CCA_EU from https://github.com/JingyanYu/LandUseDecisions/blob/9bd4747ca46c199b63d7936d16e259e46afff9ec/A%20data-driven%20framework%20to%20manage%20uncertainty/CCA_EU.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d112bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb2208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7299a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CCA_EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a48968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3804dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global value\n",
    "nodata_value = -200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415d4c4",
   "metadata": {},
   "source": [
    "# 2. FUA, GHSL data\n",
    "\n",
    "The GHSL built-up raster data publicly available with identifiers doi: 10.2905/jrc-ghsl-10007    \n",
    "The functional urban area data publicly available with identifier:10.2905/347F0337-F2DA-4592-87B3-E25975EC2C95\n",
    "Functional urban area vector data: https://ghsl.jrc.ec.europa.eu/ghs_fua.php\n",
    "\n",
    "Download the data into a (new) \"data\" folder and unzip. Then run the cell below to preprocess the data. \n",
    "\n",
    "Alternatively, you can skip this step and download preprocessed \"pickles\" instead:\n",
    "The processed GeoDataFrame of European functional urban areas & growth - the file countries_gpd.pkl can be downloaded at https://figshare.com/s/245ad30270bd7eb12f41. \n",
    "You will also need to download pre-processes raster data found here: https://figshare.com/s/406b4f8506dfdb80e9b6\n",
    "After downloading the files, copy to a (new) \"pickled_data\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cde228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the input data \n",
    "ghs_built_raster_paths = [r'data\\GHS_BUILT_LDS1975_GLOBE_R2018A_54009_250_V2_0\\GHS_BUILT_LDS1975_GLOBE_R2018A_54009_250_V2_0.tif',\n",
    "                          r'data\\GHS_BUILT_LDS1990_GLOBE_R2018A_54009_250_V2_0\\GHS_BUILT_LDS1990_GLOBE_R2018A_54009_250_V2_0.tif',\n",
    "                          r'data\\GHS_BUILT_LDS2000_GLOBE_R2018A_54009_250_V2_0\\GHS_BUILT_LDS2000_GLOBE_R2018A_54009_250_V2_0.tif',\n",
    "                          r'data\\GHS_BUILT_LDS2014_GLOBE_R2018A_54009_250_V2_0\\GHS_BUILT_LDS2014_GLOBE_R2018A_54009_250_V2_0.tif']\n",
    "\n",
    "fua_path = r'data\\GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0\\GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.gpkg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74987fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to binary reclassify GHSL urban percentage to binary urban, using 20% threshold\n",
    "def categorize_urban_vec(percent):\n",
    "    threshold = 20\n",
    "    out = np.full_like(percent, nodata_value)\n",
    "    out[(percent >= 0) & (percent < threshold) ] = 0\n",
    "    out[percent >= threshold] = 1\n",
    "    return out\n",
    "\n",
    "\n",
    "# List of countries of interest\n",
    "countries = ['Austria','CzechRepublic', 'Denmark', 'Estonia', 'Finland', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Luxembourg', 'Norway', 'Poland', 'Portugal', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'Turkey']+['France','UnitedKingdom','Netherlands',\n",
    "             'Belgium','Germany']\n",
    "\n",
    "# Read the FUA file with global FUA's\n",
    "fua_gdf = gpd.read_file(fua_path)\n",
    "\n",
    "# Restrict dataset to countries and columns of interest\n",
    "countries_gpd = fua_gdf[fua_gdf['Cntry_name'].isin(countries)]\n",
    "countries_gpd = countries_gpd[['eFUA_name','Cntry_name','FUA_area','UC_area','geometry']]\n",
    "\n",
    "#create columns - urban units at 1975, 1990, 2000, 2014,and urban growth between 75-90, 90-00, 00-14\n",
    "def add_raster_to_dataframe(dataframe, raster_path, column_name):\n",
    "        def process(x):\n",
    "            shape = x['geometry']\n",
    "            with rio.open(raster_path) as src:    \n",
    "                out_img, out_transform = mask(src, [shape], crop=True)\n",
    "            fua_urban_raster = np.squeeze(categorize_urban_vec(out_img))\n",
    "            try:\n",
    "                x[column_name] = np.unique(fua_urban_raster,return_counts=True)[1][2]\n",
    "            except:\n",
    "                x[column_name] = np.nan\n",
    "            try:\n",
    "                x['Transform'] = out_transform;\n",
    "            except:\n",
    "                x['Transform'] = np.nan\n",
    "            try:\n",
    "                x[column_name + ' raster'] = fua_urban_raster.copy();\n",
    "            except:\n",
    "                x[column_name + ' raster'] = np.nan\n",
    "            return x\n",
    "        \n",
    "        dataframe = dataframe.apply(process, axis=1)\n",
    "        return dataframe\n",
    "        \n",
    "countries_gpd = add_raster_to_dataframe(countries_gpd, ghs_built_raster_paths[0],'1975 urban')\n",
    "countries_gpd = add_raster_to_dataframe(countries_gpd, ghs_built_raster_paths[1],'1990 urban')\n",
    "countries_gpd = add_raster_to_dataframe(countries_gpd, ghs_built_raster_paths[2],'2000 urban')\n",
    "countries_gpd = add_raster_to_dataframe(countries_gpd, ghs_built_raster_paths[3],'2014 urban')\n",
    "\n",
    "# Remove missing data\n",
    "countries_gpd.dropna(inplace=True)\n",
    "\n",
    "# Pre-calculate urban growth quantities\n",
    "countries_gpd['90-00 UG'] = countries_gpd['2000 urban']-countries_gpd['1990 urban'] \n",
    "countries_gpd['00-14 UG'] = countries_gpd['2014 urban']-countries_gpd['2000 urban'] \n",
    "countries_gpd['75-90 UG'] = countries_gpd['1990 urban']-countries_gpd['1975 urban'] \n",
    "\n",
    "#Keep only the FUAs with urban growth\n",
    "countries_gpd = countries_gpd[(countries_gpd['75-90 UG']>0)&(countries_gpd['90-00 UG']>0)&(countries_gpd['00-14 UG']>0)]\n",
    "\n",
    "# putting the rasters in separate lists \n",
    "categorized_FUA_1975s = countries_gpd['1975 urban raster'].to_list()\n",
    "categorized_FUA_1990s = countries_gpd['1990 urban raster'].to_list()\n",
    "categorized_FUA_2000s = countries_gpd['2000 urban raster'].to_list()\n",
    "categorized_FUA_2014s = countries_gpd['2014 urban raster'].to_list()\n",
    "\n",
    "# the affine transforms are identical from year to year, so this can be simplified\n",
    "transforms = countries_gpd['Transform'].to_list()\n",
    "\n",
    "# remove rasters from gpd \n",
    "countries_gpd = countries_gpd.drop(columns=['1975 urban raster'])\n",
    "countries_gpd = countries_gpd.drop(columns=['1990 urban raster'])\n",
    "countries_gpd = countries_gpd.drop(columns=['2000 urban raster'])\n",
    "countries_gpd = countries_gpd.drop(columns=['2014 urban raster'])\n",
    "countries_gpd = countries_gpd.drop(columns=['Transform'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3e9fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store preprocessed data in pickles\n",
    "if not os.path.isdir(\"pickled_data\"):\n",
    "    os.makedirs(\"pickled_data\")\n",
    "    \n",
    "with open(r\"pickled_data\\categorized_FUA_1975s.pickle\", 'wb') as f:\n",
    "    pickle.dump(categorized_FUA_1975s, f)\n",
    "with open(r\"pickled_data\\categorized_FUA_1990s.pickle\", 'wb') as f:\n",
    "    pickle.dump(categorized_FUA_1990s, f)\n",
    "with open(r\"pickled_data\\categorized_FUA_2000s.pickle\", 'wb') as f:\n",
    "    pickle.dump(categorized_FUA_2000s, f)\n",
    "with open(r\"pickled_data\\categorized_FUA_2014s.pickle\", 'wb') as f:\n",
    "    pickle.dump(categorized_FUA_2014s, f)\n",
    "with open(r\"pickled_data\\out_transforms1975.pkl\", 'wb') as f:\n",
    "    pickle.dump(transforms, f)\n",
    "with open(r\"pickled_data\\out_transforms2014.pkl\", 'wb') as f:\n",
    "    pickle.dump(transforms, f)\n",
    "countries_gpd.to_pickle(r\"pickled_data\\countries_gpd.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read preprocessed data from pickles\n",
    "countries_gpd = pd.read_pickle(r\"pickled_data\\countries_gpd.pkl\")\n",
    "with open(r'pickled_data\\categorized_FUA_1975s.pickle', 'rb') as handle:\n",
    "    categorized_FUA_1975s = pickle.load(handle)\n",
    "with open(r'pickled_data\\categorized_FUA_1990s.pickle', 'rb') as handle:\n",
    "    categorized_FUA_1990s = pickle.load(handle)\n",
    "with open(r'pickled_data\\categorized_FUA_2000s.pickle', 'rb') as handle:\n",
    "     categorized_FUA_2000s = pickle.load(handle)\n",
    "with open(r'pickled_data\\categorized_FUA_2014s.pickle', 'rb') as handle:\n",
    "     categorized_FUA_2014s = pickle.load(handle)\n",
    "with open(r'pickled_data\\out_transforms1975.pkl', 'rb') as f:\n",
    "    transforms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd5664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show first few lines of table\n",
    "countries_gpd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b85923",
   "metadata": {},
   "source": [
    "# 3. Use CCA\n",
    "\n",
    "The parameters by scenarios can be found at: https://doi.org/10.6084/m9.figshare.22194244.v1\n",
    "\n",
    "After downloading, copy the parameters to a \"parameters\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b95139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parameters for modelling growth using the four spatial development scenarios \n",
    "\n",
    "paras_fourscenarios = np.load(r'parameters\\paras_fourscenarios.npy',allow_pickle=True)\n",
    "seeds_fourscenarios = np.load(r'parameters\\seeds_fourscenarios.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model\n",
    "\n",
    "# Choose a scenario:\n",
    "# 0 - compact; 1 - medium compact; 2 - medium dispersed; 3 - dispersed\n",
    "# here we choose 3 - dispersed\n",
    "scenario_no = 3 \n",
    "\n",
    "# Get a random parameter set for the chosen scenario\n",
    "idx = np.random.randint(len(paras_fourscenarios[scenario_no]))\n",
    "paras = paras_fourscenarios[scenario_no][idx]\n",
    "seed = seeds_fourscenarios[scenario_no][idx]\n",
    "\n",
    "# Margate(UK) has index 649 in the FUA database\n",
    "fua_index = 649\n",
    "\n",
    "# We will similate growth starting from 1975 and for the amount of growth that we \n",
    "# historically saw over the 75-90 period\n",
    "total_growth = int(countries_gpd.iloc[fua_index]['75-90 UG'])\n",
    "print('Amount of growth: ' + str(total_growth))\n",
    "\n",
    "# Get the inital urban outline map of Margate from the preprocessed data \n",
    "initial_map = categorized_FUA_1975s[fua_index].copy()\n",
    "rows, cols = initial_map.shape\n",
    "\n",
    "# for display, replace nodata with 0\n",
    "display_map = initial_map.copy()\n",
    "display_map[initial_map == nodata_value] = 0\n",
    "show(display_map)\n",
    "\n",
    "# set the increment size (default = 15)\n",
    "growth_per_step = 15\n",
    "\n",
    "# apply the model\n",
    "final_map = CCA_EU.CCA_last_snapshot([paras[0],0,paras[1]],[0,paras[2],paras[3]],\n",
    "                                  seed=seed,landmap=initial_map.copy(),\n",
    "                                  rows=rows,cols=cols,urban_num=total_growth,trans_num=growth_per_step)\n",
    "# Show the outline of Margate\n",
    "countries_gpd.iloc[fua_index].geometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize change plots\n",
    "\n",
    "def plot_change(before, after, transform, axis, title):\n",
    "    changes_colours = ListedColormap(['none','r'])\n",
    "    cmap = ListedColormap([\"none\",\"none\", \"grey\"])\n",
    "    b = before.copy()\n",
    "    a = after.copy()\n",
    "    b[b==-200] = 0\n",
    "    a[a==-200] = 0\n",
    "    show(a, ax = axis, transform = transform, cmap = cmap )\n",
    "    changes = a - b\n",
    "    show(changes,ax=axis,cmap=changes_colours,transform=transform)\n",
    "    axis.tick_params(labelbottom=False,labelleft=False,axis=u'both', which=u'both',length=0)\n",
    "    axis.set_title(title)\n",
    "    return\n",
    "\n",
    "after = categorized_FUA_1990s[fua_index]\n",
    "transform = transforms[fua_index]\n",
    "fig, axes = plt.subplots(1,2,figsize=(10,4))\n",
    "plot_change(initial_map, after, transform, axes[0], 'Real Changes')\n",
    "plot_change(initial_map, final_map, transform, axes[1], 'Simulated Changes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38fed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final map to \"final_map.tif\"\n",
    "# This will use the projection system from ghsl\n",
    "\n",
    "with rio.Env():\n",
    "    with rio.open(ghs_built_raster_paths[0]) as src_dataset:\n",
    "        profile = src_dataset.profile\n",
    "        profile.update(\n",
    "            driver = 'GTiff',\n",
    "            dtype = rio.int16,\n",
    "            count = 1,\n",
    "            compress= 'lzw',\n",
    "            width = cols,\n",
    "            height = rows,\n",
    "            transform = transforms[fua_index])\n",
    "    with rio.open('final_map.tif', 'w', **profile) as dst_dataset:\n",
    "        dst_dataset.write(final_map.astype(rio.int16), 1)        \n",
    "    with rio.open('initial_map.tif', 'w', **profile) as dst_dataset:\n",
    "        dst_dataset.write(initial_map.astype(rio.int16), 1)        \n",
    "    with rio.open('after_map.tif', 'w', **profile) as dst_dataset:\n",
    "        dst_dataset.write(after.astype(rio.int16), 1)        \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export FUA outline to shapefile\n",
    "single_fua = countries_gpd.iloc[[fua_index],:]\n",
    "single_fua.to_file(\"fua_outline.shp\")                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72d545",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "1. Parameters for four scenarios\n",
    "\n",
    "The original parameters can be found at: https://figshare.com/s/650730f9e6fedc44ac1a   \n",
    "The parameters by scenarios can be found at: https://doi.org/10.6084/m9.figshare.22194244.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435245ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parameters for urban spatial development scenarios projection\n",
    "# The parameters can be found at: https://figshare.com/s/650730f9e6fedc44ac1a\n",
    "paths = [ r'results_EU\\pattern_kl\\Avignon_m_chain2.npy',r'results_EU\\pattern_kl\\Poitiers_m_chain2.npy',\n",
    "         r'results_EU\\pattern_kl\\Belfast_m_chain2.npy',r'results_EU\\pattern_kl\\Blackwater_m_chain2.npy',\n",
    "         r'results_EU\\pattern_kl\\Enschede_m_chain2.npy',r'results_EU\\pattern_kl\\Utrecht_m_chain2.npy',\n",
    "         r'results_EU\\pattern_kl\\Leuven_m_chain2.npy', r'results_EU\\pattern_kl\\Mons_m_chain2.npy', \n",
    "         r'results_EU\\pattern_kl\\Mönchengladbach_m_chain2.npy',r'results_EU\\pattern_kl\\Wuppertal_m_chain2.npy']\n",
    "\n",
    "chains = [np.load(path,allow_pickle=True) for path in paths]\n",
    "paras_best20_pattern = [chain[0][chain[2].argsort()[:20]] for chain in chains]\n",
    "seeds_best20_pattern = [chain[1][chain[2].argsort()[:20]] for chain in chains]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b475255",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [ r'results_EU\\changes_kl\\Avignon_m_chain2.npy',r'results_EU\\changes_kl\\Poitiers_m_chain2.npy',\n",
    "         r'results_EU\\changes_kl\\Belfast_m_chain2.npy',r'results_EU\\changes_kl\\Blackwater_m_chain2.npy',\n",
    "         r'results_EU\\changes_kl\\Enschede_m_chain2.npy',r'results_EU\\changes_kl\\Utrecht_m_chain2.npy',\n",
    "         r'results_EU\\changes_kl\\Leuven_m_chain2.npy',r'results_EU\\changes_kl\\Mons_m_chain2.npy', \n",
    "         r'results_EU\\changes_kl\\Mönchengladbach_m_chain2.npy',r'results_EU\\changes_kl\\Wuppertal_m_chain2.npy']\n",
    "\n",
    "chains = [np.load(path,allow_pickle=True) for path in paths]\n",
    "paras_best20_change = [chain[0][chain[2].argsort()[:20]] for chain in chains]\n",
    "seeds_best20_change = [chain[1][chain[2].argsort()[:20]] for chain in chains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f00bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_compact = np.concatenate([paras_best20_pattern[1], paras_best20_pattern[2],paras_best20_change[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_compact = np.concatenate([seeds_best20_pattern[1], seeds_best20_pattern[2],seeds_best20_change[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_mediumcompact = np.concatenate([paras_best20_pattern[-1], paras_best20_pattern[4],\n",
    "                                      paras_best20_pattern[0],paras_best20_pattern[3],\n",
    "                                      paras_best20_change[1],paras_best20_change[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_mediumcompact = np.concatenate([seeds_best20_pattern[-1], seeds_best20_pattern[4],\n",
    "                                      seeds_best20_pattern[0],seeds_best20_pattern[3],\n",
    "                                      seeds_best20_change[1],seeds_best20_change[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72087e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_mediumdispersed = np.concatenate([paras_best20_pattern[5], paras_best20_pattern[-2],\n",
    "                                      paras_best20_pattern[-3],paras_best20_change[0],\n",
    "                                      paras_best20_change[-1],paras_best20_change[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad13d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_mediumdispersed = np.concatenate([seeds_best20_pattern[5], seeds_best20_pattern[-2],\n",
    "                                      seeds_best20_pattern[-3],seeds_best20_change[0],\n",
    "                                      seeds_best20_change[-1],seeds_best20_change[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60cd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_dispersed = np.concatenate([paras_best20_pattern[-4], \n",
    "                                      paras_best20_change[-4],paras_best20_change[-3],\n",
    "                                      paras_best20_change[3],paras_best20_change[-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_dispersed = np.concatenate([seeds_best20_pattern[-4], \n",
    "                                      seeds_best20_change[-4],seeds_best20_change[-3],\n",
    "                                      seeds_best20_change[3],seeds_best20_change[-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39806a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_fourscenarios = [paras_compact,paras_mediumcompact,paras_mediumdispersed,paras_dispersed]\n",
    "seeds_fourscenarios = [seeds_compact,seeds_mediumcompact,seeds_mediumdispersed,seeds_dispersed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('paras_fourscenarios.npy',paras_fourscenarios)\n",
    "np.save('seeds_fourscenarios.npy',seeds_fourscenarios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
